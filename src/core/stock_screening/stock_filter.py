"""
â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—
â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â•šâ•â•â–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—      â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘
â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ•”â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ•â•â•â•â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘
â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘
â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•       â•šâ•â•â•â•â•â•  â•šâ•â•â•â•â•â• â•šâ•â•     â•šâ•â•

ðŸ”ï¸ ALGORITHMIC TRADING SYSTEM - "They delved too greedily and too deep..."

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ðŸ“‹ MODULE: Three-Layer Stock Screening                                         â”‚
â”‚ ðŸ“„ FILE: stock_filter.py                                                       â”‚
â”‚ ðŸ“… CREATED: 2024-12-21                                                             â”‚
â”‚ ðŸ‘‘ AUTHOR: FeanorKingofNoldor                                                      â”‚
â”‚ ðŸ”— REPOSITORY: https://github.com/FeanorKingofNoldor/khazad_dum                   â”‚
â”‚ ðŸ“§ CONTACT: [Your Contact Info]                                                    â”‚
â”‚                                                                                     â”‚
â”‚ ðŸŽ¯ PURPOSE:                                                                        â”‚
â”‚ Research-validated three-layer filtering: hard constraints, regime scoring, selection â”‚
â”‚                                                                                     â”‚
â”‚ ðŸ”§ DEPENDENCIES:                                                                   â”‚
â”‚ - pandas (data manipulation)                                                       â”‚
â”‚ - numpy (numeric operations)                                                       â”‚
â”‚ - SQLite database (filter results storage)                                        â”‚
â”‚ - regime-adaptive scoring algorithms                                               â”‚
â”‚                                                                                     â”‚
â”‚ ðŸ“ˆ TRADING PIPELINE STAGE: 2. Stock Screening                                   â”‚
â”‚ â””â”€â”€ 1. Market Regime Detection                                                     â”‚
â”‚ â””â”€â”€ 2. Stock Screening â† YOU ARE HERE                                           â”‚
â”‚ â””â”€â”€ 3. AI Analysis (TradingAgents)                                                 â”‚
â”‚ â””â”€â”€ 4. Pattern Recognition                                                         â”‚
â”‚ â””â”€â”€ 5. Portfolio Construction                                                      â”‚
â”‚ â””â”€â”€ 6. Performance Observation                                                     â”‚
â”‚                                                                                     â”‚
â”‚ âš ï¸  CRITICAL NOTES:                                                                â”‚
â”‚ - Reduces thousands of stocks to ~30 candidates                                   â”‚
â”‚ - Regime-adaptive scoring: fear = mean reversion, greed = momentum                â”‚
â”‚ - Includes exploration component to avoid overfitting                             â”‚
â”‚                                                                                     â”‚
â”‚ ðŸ“Š PERFORMANCE NOTES:                                                              â”‚
â”‚ - Layer 1: Eliminates 80-95% of stocks instantly                                 â”‚
â”‚ - Layer 2: Regime-based scoring in ~100ms                                        â”‚
â”‚ - Layer 3: Final selection with exploration ratio                                â”‚
â”‚                                                                                     â”‚
â”‚ ðŸ§ª TESTING:                                                                        â”‚
â”‚ - Unit Tests: tests/unit/test_stock_filter.py                                     â”‚
â”‚ - Integration Tests: tests/integration/test_stock_screening_integration.py        â”‚
â”‚                                                                                     â”‚
â”‚ ðŸ“š DOCUMENTATION:                                                                  â”‚
â”‚ - API Docs: Auto-generated from docstrings                                        â”‚
â”‚ - Usage Guide: docs/guides/STOCK_SCREENING_USAGE.md                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Licensed under MIT License - See LICENSE file for details
Copyright (c) 2024 FeanorKingofNoldor

"In the depths of Khazad-dÃ»m, the markets reveal their secrets to those who dare..."
"""

import pandas as pd
import numpy as np
from typing import List, Dict
from datetime import datetime

from config.settings.base_config import (
    MIN_DOLLAR_VOLUME,
    MIN_MARKET_CAP,
    MIN_PRICE,
    FILTER_PERCENTILES,
    EXPLORATION_RATIO
)


class StockFilter:
    """
    Three-layer filter to reduce thousands of stocks to 30 candidates
    """
    
    def __init__(self, database):
        self.db = database
        self.min_dollar_volume = MIN_DOLLAR_VOLUME
        self.min_market_cap = MIN_MARKET_CAP
        self.min_price = MIN_PRICE
        self.exploration_ratio = EXPLORATION_RATIO
    
    def run_full_filter(self, regime: Dict) -> pd.DataFrame:
        """
        Run complete 3-layer filtering process
        """
        print("\nRunning 3-Layer Filter...")
        
        # Get latest stock data from database
        all_stocks = self.db.get_latest_metrics()
        
        if all_stocks.empty:
            print("No stocks in database to filter")
            return pd.DataFrame()
        
        print(f"Starting with {len(all_stocks)} stocks")
        
        # Layer 1: Hard constraints
        layer1 = self.apply_hard_constraints(all_stocks)
        print(f"Layer 1 (Hard constraints): {len(layer1)} stocks remain")
        
        # Layer 2: Regime-based scoring
        layer2 = self.apply_regime_scoring(layer1, regime)
        print(f"Layer 2 (Regime scoring): Scored {len(layer2)} stocks")
        
        # Layer 3: Select final candidates
        final = self.select_candidates(layer2, regime)
        print(f"Layer 3 (Final selection): {len(final)} candidates")
        
        # Save filter results to database
        self.save_filter_results(final, regime)
        
        return final
    
    def apply_hard_constraints(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Layer 1: Remove untradeable stocks
        Research shows this eliminates 80-95% with minimal false negatives
        """
        filtered = df[
            (df['dollar_volume'] > self.min_dollar_volume) &
            (df['price'] > self.min_price)
            # Market cap check disabled since we're estimating it
        ]
        return filtered
    
    def apply_regime_scoring(self, df: pd.DataFrame, regime: Dict) -> pd.DataFrame:
        """
        Layer 2: Score based on current regime
        Weights from research findings
        """
        df = df.copy()
        
        if regime['regime'] in ['extreme_fear', 'fear']:
            # Mean reversion scoring
            df['score'] = (
                0.5 * (30 - df['rsi_2'].clip(0, 30)) / 30 +  # Lower RSI better
                0.3 * df['quality_score'] +                    # Quality matters
                0.2 * df['volume_ratio'].clip(0, 3) / 3       # Volume spike
            )
            
        elif regime['regime'] in ['greed', 'extreme_greed']:
            # Momentum scoring (current regime!)
            df['score'] = (
                0.4 * (df['rsi_2'].clip(50, 100) - 50) / 50 +  # Higher RSI better
                0.3 * df['volume_ratio'].clip(0, 2) / 2 +       # Volume confirmation
                0.3 * df['quality_score']                        # Quality always matters
            )
            
            # Bonus for price above moving average
            if 'sma_20' in df.columns:
                df['above_ma'] = (df['price'] > df['sma_20']).astype(float)
                df['score'] = df['score'] * 0.8 + df['above_ma'] * 0.2
        
        else:  # neutral
            # Balanced scoring
            df['score'] = (
                0.33 * df['quality_score'] +
                0.33 * df['volume_ratio'].clip(0, 2) / 2 +
                0.34 * (50 - abs(df['rsi_2'] - 50)) / 50  # Neutral RSI
            )
        
        return df.sort_values('score', ascending=False)
    
    def select_candidates(self, df: pd.DataFrame, regime: Dict, max_stocks: int = 30) -> pd.DataFrame:
        """
        Layer 3: Select final candidates based on regime percentiles
        Research validated thresholds
        """
        if df.empty:
            return df
        
        # Get percentile threshold for this regime
        percentile = FILTER_PERCENTILES[regime['regime']]
        threshold_score = np.percentile(df['score'], percentile)
        
        # Select stocks above threshold
        candidates = df[df['score'] >= threshold_score]
        
        # Add exploration (15% random from remaining)
        remaining = df[df['score'] < threshold_score]
        if len(remaining) > 0:
            n_explore = min(int(max_stocks * self.exploration_ratio), len(remaining))
            exploration = remaining.sample(n=min(n_explore, len(remaining)))
            candidates = pd.concat([candidates, exploration])
        
        # Limit to max stocks
        final = candidates.nlargest(min(max_stocks, len(candidates)), 'score')
        
        # Add selection metadata
        final['selected'] = True
        final['selection_reason'] = final.apply(
            lambda x: 'top_score' if x['score'] >= threshold_score else 'exploration',
            axis=1
        )
        
        return final
    
    def save_filter_results(self, df: pd.DataFrame, regime: Dict):
        """
        Save filter results for tracking
        """
        if df.empty:
            return
        
        for _, row in df.iterrows():
            self.db.conn.execute("""
            INSERT OR REPLACE INTO filter_results 
            (timestamp, symbol, score, regime, selected)
            VALUES (?, ?, ?, ?, ?)
            """, (
                datetime.now(),
                row['symbol'],
                row['score'],
                regime['regime'],
                True
            ))
        self.db.conn.commit()
    
    def get_filter_stats(self) -> Dict:
        """
        Get statistics about filter performance
        """
        query = """
        SELECT 
            regime,
            COUNT(*) as total_selected,
            AVG(score) as avg_score,
            MAX(score) as max_score
        FROM filter_results
        WHERE selected = 1
        GROUP BY regime
        """
        
        df = pd.read_sql(query, self.db.conn)
        return df.to_dict('records')